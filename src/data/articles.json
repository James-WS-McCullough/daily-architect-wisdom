{
  "inspiration": [
    {
      "title": "Act with Prudence",
      "author": "Seb Rose",
      "content": "> Whatever you undertake, act with prudence and consider the consequences.\n~Anon\n\nNo matter how comfortable a schedule looks at the beginning of an iteration, you can’t avoid being under pressure some of the time. If you find yourself having to choose between “doing it right” and “doing it quick,” it is often appealing to “do it quick” with the understanding that you’ll come back and fix it later. When you make this promise to yourself, your team, and your customer, you mean it. But all too often, the next iteration brings new problems and you become focused on them. This sort of deferred work is known as technical debt, and it is not your friend. Specifically, Martin Fowler calls this deliberate technical debt in his taxonomy of technical debt,* and it should not be confused with inadvertent technical debt.\n\nTechnical debt is like a loan: you benefit from it in the short term, but you have to pay interest on it until it is fully paid off. Shortcuts in the code make it harder to add features or refactor your code. They are breeding grounds for defects and brittle test cases. The longer you leave it, the worse it gets. By the time you get around to undertaking the original fix, there may be a whole stack of not-quite-right design choices layered on top of the original problem, making the code much harder to refactor and correct. In fact, it is often only when things have got so bad that you must fix the original problem, that you actually do go back to fix it. And by then, it is often so hard to fix that you really can’t afford the time or the risk.\n\nThere are times when you must incur technical debt to meet a deadline or implement a thin slice of a feature. Try not to be in this position, but if the situation absolutely demands it, then go ahead. But (and this is a big but) you must track technical debt and pay it back quickly, or things go rapidly downhill.\n\nAs soon as you make the decision to compromise, write a task card or log it in your issue-tracking system to ensure that it does not get forgotten.\n\nIf you schedule repayment of the debt in the next iteration, the cost will be minimal. Leaving the debt unpaid will accrue interest, and that interest should be tracked to make the cost visible. This will emphasize the effect on business value of the project’s technical debt and enables appropriate prioritization of the repayment. The choice of how to calculate and track the interest will depend on the particular project, but track it you must.\n\nPay off technical debt as soon as possible. It would be imprudent to do otherwise."
    },
    {
      "title": "Apply Functional Programming Principles",
      "author": "Edward Garson",
      "content": "Functional programming has recently enjoyed renewed interest from the mainstream programming community. Part of the reason is because emergent properties of the functional paradigm are well positioned to address the challenges posed by our industry’s shift toward multicore. However, while that is certainly an important application, it is not the reason this piece admonishes you to know thy functional programming.\n\nMastery of the functional programming paradigm can greatly improve the quality of the code you write in other contexts. If you deeply understand and apply the functional paradigm, your designs will exhibit a much higher degree of referential transparency.\n\nReferential transparency is a very desirable property: it implies that functions consistently yield the same results given the same input, irrespective of where and when they are invoked. That is, function evaluation depends less—ideally, not at all—on the side effects of mutable state.\n\nA leading cause of defects in imperative code is attributable to mutable variables. Everyone reading this will have investigated why some value is not as expected in a particular situation. Visibility semantics can help to mitigate these insidious defects, or at least to drastically narrow down their location, but their true culprit may in fact be the providence of designs that employ inordinate mutability.\n\nAnd we certainly don’t get much help from the industry in this regard. Introductions to object orientation tacitly promote such design, because they often show examples composed of graphs of relatively long-lived objects that happily call mutator methods on one another, which can be ­ dangerous.\n\nHowever, with astute test-driven design, particularly when being sure to “Mock Roles, not Objects,” unnecessary mutability can be designed away.\n\nThe net result is a design that typically has better responsibility allocation with more numerous, smaller functions that act on arguments passed into them, rather than referencing mutable member variables. There will be fewer defects, and furthermore they will often be simpler to debug, because it is easier to locate where a rogue value is introduced in these designs than to otherwise deduce the particular context that results in an erroneous assignment. This adds up to a much higher degree of referential transparency, and positively nothing will get these ideas as deeply into your bones as learning a functional programming language, where this model of computation is the norm.\n\nOf course, this approach is not optimal in all situations. For example, in objectoriented systems, this style often yields better results with domain model development (i.e., where collaborations serve to break down the complexity of business rules) than with user-interface development.\n\nMaster the functional programming paradigm so you are able to judiciously apply the lessons learned to other domains. Your object systems (for one) will resonate with referential transparency goodness and be much closer to their functional counterparts than many would have you believe. In fact, some would even assert that, at their apex, functional programming and object orientation are merely a reflection of each other, a form of computational yin and yang."
    },
    {
      "title": "Ask, “What Would the User Do?” (You Are Not the User)",
      "author": "Giles Colborne",
      "content": "We all tend to assume that other people think like us. But they don’t. Psychologists call this the false consensus bias. When people think or act differently from us, we’re quite likely to label them (subconsciously) as defective in some way.\n\nThis bias explains why programmers have such a hard time putting themselves in the users’ position. Users don’t think like programmers. For a start, they spend much less time using computers. They neither know nor care how a computer works. This means they can’t draw on any of the battery of problem-solving techniques so familiar to programmers. They don’t recognize the patterns and cues programmers use to work with, through, and around an interface.\n\nThe best way to find out how a user thinks is to watch one. Ask a user to complete a task using a similar piece of software to what you’re developing.\n\nMake sure the task is a real one: “Add up a column of numbers” is OK; “Calculate your expenses for the last month” is better. Avoid tasks that are too specific, such as “Can you select these spreadsheet cells and enter a SUM formula below?”—there’s a big clue in that question. Get the user to talk through his or her progress. Don’t interrupt. Don’t try to help. Keep asking yourself, “Why is he doing that?” and “Why is she not doing that?” The first thing you’ll notice is that users do a core of things similarly. They try to complete tasks in the same order—and they make the same mistakes in the same places. You should design around that core behavior. This is different from design meetings, where people tend to listen when someone says, “What if the user wants to…?” This leads to elaborate features and confusion over what users want. Watching users eliminates this confusion.\n\nYou’ll see users getting stuck. When you get stuck, you look around. When users get stuck, they narrow their focus. It becomes harder for them to see solutions elsewhere on the screen. It’s one reason why help text is a poor solution to poor user interface design. If you must have instructions or help text, make sure to locate it right next to your problem areas. A user’s narrow focus of attention is why tool tips are more useful than help menus.\n\nUsers tend to muddle through. They’ll find a way that works and stick with it, no matter how convoluted. It’s better to provide one really obvious way of doing things than two or three shortcuts.\n\nYou’ll also find that there’s a gap between what users say they want and what they actually do. That’s worrying, as the normal way of gathering user requirements is to ask them. It’s why the best way to capture requirements is to watch users. Spending an hour watching users is more informative than spending a day guessing what they want."
    },
    {
      "title": "Automate Your Coding Standard",
      "author": "Filip van Laenen",
      "content": "You’ve probably been there, too. At the beginning of a project, everybody has lots of good intentions—call them “new project’s resolutions.” Quite often, many of these resolutions are written down in documents. The ones about code end up in the project’s coding standard. During the kick-off meeting, the lead developer goes through the document and, in the best case, everybody agrees that they will try to follow them. Once the project gets underway, though, these good intentions are abandoned, one at a time. When the project is finally delivered, the code looks like a mess, and nobody seems to know how it came to be that way.\n\nWhen did things go wrong? Probably already at the kick-off meeting. Some of the project members didn’t pay attention. Others didn’t understand the point.\n\nWorse, some disagreed and were already planning their coding standard rebellion. Finally, some got the point and agreed, but when the pressure in the project got too high, they had to let something go. Well-formatted code doesn’t earn you points with a customer that wants more functionality. Furthermore, following a coding standard can be quite a boring task if it isn’t automated. Just try to indent a messy class by hand to find out for yourself.\n\nBut if it’s such a problem, why is it that we want a coding standard in the first place? One reason to format the code in a uniform way is so that nobody can “own” a piece of code just by formatting it in his or her private way. We may want to prevent developers from using certain antipatterns in order to avoid some common bugs. In all, a coding standard should make it easier to work in the project, and maintain development speed from the beginning to the end.\n\nIt follows, then, that everybody should agree on the coding standard, too—it does not help if one developer uses three spaces to indent code, and another uses four.\n\nThere exists a wealth of tools that can be used to produce code quality reports and to document and maintain the coding standard, but that isn’t the whole solution. It should be automated and enforced where possible. Here are a few examples:\n\n- Make sure code formatting is part of the build process, so that everybody runs it automatically every time they compile the code.\n\n- Use static code analysis tools to scan the code for unwanted antipatterns.\n\nIf any are found, break the build.\n\n- Learn to configure those tools so that you can scan for your own, projectspecific antipatterns.\n\n- Do not only measure test coverage, but automatically check the results, too. Again, break the build if test coverage is too low.\n\nTry to do this for everything that you consider important. You won’t be able to automate everything you really care about. As for the things that you can’t automatically flag or fix, consider them a set of guidelines supplementary to the coding standard that is automated, but accept that you and your colleagues may not follow them as diligently.\n\nFinally, the coding standard should be dynamic rather than static. As the project evolves, the needs of the project change, and what may have seemed smart in the beginning isn’t necessarily smart a few months later."
    },
    {
      "title": "Beauty Is in Simplicity",
      "author": "Jørn Ølmheim",
      "content": "There is one quote, from plato, that I think is particularly good for all software developers to know and keep close to their hearts: *beauty of style and harmony and grace and good rhythm depends on simplicity.*\n\nIn one sentence, this sums up the values that we as software developers should aspire to.\n\nThere are a number of things we strive for in our code:\n\n- Readability\n\n- Maintainability\n\n- Speed of development\n\n- The elusive quality of beauty Plato is telling us that the enabling factor for all of these qualities is simplicity.\n\nWhat is beautiful code? This is potentially a very subjective question. Perception of beauty depends heavily on individual background, just as much of our perception of anything depends on our background. People educated in the arts have a different perception of (or at least approach to) beauty than people educated in the sciences. Arts majors tend to approach beauty in software by comparing software to works of art, while science majors tend to talk about symmetry and the golden ratio, trying to reduce things to formulae.\n\nIn my experience, simplicity is the foundation of most of the arguments from both sides.\n\nThink about source code that you have studied. If you haven’t spent time studying other people’s code, stop reading this right now and find some open source code to study. Seriously! I mean it! Go search the Web for some code in your language of choice, written by some well-known, acknowledged expert.\n\nYou’re back? Good. Where were we? Ah, yes…I have found that code that resonates with me, and that I consider beautiful, has a number of properties in common. Chief among these is simplicity. I find that no matter how complex the total application or system is, the individual parts have to be kept simple: simple objects with a single responsibility containing similarly simple, focused methods with descriptive names. Some people think the idea of having short methods of 5–10 lines of code is extreme, and some languages make it very hard to do, but I think that such brevity is a desirable goal nonetheless.\n\nThe bottom line is that beautiful code is simple code. Each individual part is kept simple with simple responsibilities and simple relationships with the other parts of the system. This is the way we can keep our systems maintainable over time, with clean, simple, testable code, ensuring a high speed of development throughout the lifetime of the system.\n\nBeauty is born of and found in simplicity."
    },
    {
      "title": "Before You Refactor",
      "author": "Rajith Attapattu",
      "content": "At some point , every programmer will need to refactor existing code. But before you do so, please think about the following, as this could save you and others a great deal of time (and pain):\n\n- The best approach for restructuring starts by taking stock of the existing codebase and the tests written against that code. This will help you understand the strengths and weaknesses of the code as it currently stands, so you can ensure that you retain the strong points while avoiding the mistakes. We all think we can do better than the existing system…until we end up with something no better—or even worse—than the previous incarnation because we failed to learn from the existing system’s mistakes.\n\n- Avoid the temptation to rewrite everything. It is best to reuse as much code as possible. No matter how ugly the code is, it has already been tested, reviewed, etc. Throwing away the old code—especially if it was in production—means that you are throwing away months (or years) of tested, battle-hardened code that may have had certain workarounds and bug fixes you aren’t aware of. If you don’t take this into account, the new code you write may end up showing the same mysterious bugs that were fixed in the old code. This will waste a lot of time, effort, and knowledge gained over the years.\n\n- Many incremental changes are better than one massive change. Incremental changes allows you to gauge the impact on the system more easily through feedback, such as from tests. It is no fun to see a hundred test failures after you make a change. This can lead to frustration and pressure that can in turn result in bad decisions. A couple of test failures at a time is easier to deal with, leading to a more manageable approach.\n\n- - - - After each development iteration, it is important to ensure that the existing tests pass. Add new tests if the existing tests are not sufficient to cover the changes you made. Do not throw away the tests from the old code without due consideration. On the surface, some of these tests may not appear to be applicable to your new design, but it would be well worth the effort to dig deep down into the reasons why this particular test was added.\n\nPersonal preferences and ego shouldn’t get in the way. If something isn’t broken, why fix it? That the style or the structure of the code does not meet your personal preference is not a valid reason for restructuring.\n\nThinking you could do a better job than the previous programmer is not a valid reason, either.\n\nNew technology is an insufficient reason to refactor. One of the worst reasons to refactor is because the current code is way behind all the cool technology we have today, and we believe that a new language or framework can do things a lot more elegantly. Unless a cost-benefit analysis shows that a new language or framework will result in significant improvements in functionality, maintainability, or productivity, it is best to leave it as it is.\n\nRemember that humans make mistakes. Restructuring will not always guarantee that the new code will be better—or even as good as—the previous attempt. I have seen and been a part of several failed restructuring attempts. It wasn’t pretty, but it was human."
    },
    {
      "title": "Beware the Share",
      "author": "Udi Dahan",
      "content": "It was my first project at the company . I’d just finished my degree and was anxious to prove myself, staying late every day going through the existing code. As I worked through my first feature, I took extra care to put in place everything I had learned—commenting, logging, pulling out shared code into libraries where possible, the works. The code review that I had felt so ready for came as a rude awakening—reuse was frowned upon!\n\nHow could this be? Throughout college, reuse was held up as the epitome of quality software engineering. All the articles I had read, the textbooks, the seasoned software professionals who taught me—was it all wrong?\n\nIt turns out that I was missing something critical.\n\nContext.\n\nThe fact that two wildly different parts of the system performed some logic in the same way meant less than I thought. Up until I had pulled out those libraries of shared code, these parts were not dependent on each other. Each could evolve independently. Each could change its logic to suit the needs of the system’s changing business environment. Those four lines of similar code were accidental—a temporal anomaly, a coincidence. That is, until I came along.\n\nThe libraries of shared code I created tied the shoelaces of each foot to the other. Steps by one business domain could not be made without first synchronizing with the other. Maintenance costs in those independent functions used to be negligible, but the common library required an order of magnitude more testing.\n\nWhile I’d decreased the absolute number of lines of code in the system, I had increased the number of dependencies. The context of these dependencies is critical—had they been localized, the sharing may have been justified and had some positive value. When these dependencies aren’t held in check, their tendrils entangle the larger concerns of the system, even though the code itself looks just fine.\n\nThese mistakes are insidious in that, at their core, they sound like a good idea.\n\nWhen applied in the right context, these techniques are valuable. In the wrong context, they increase cost rather than value. When coming into an existing codebase with no knowledge of where the various parts will be used, I’m much more careful these days about what is shared.\n\nBeware the share. Check your context. Only then, proceed."
    },
    {
      "title": "The Boy Scout Rule",
      "author": "Robert C. Martin (Uncle Bob)",
      "content": "The boy scouts ha ve a rule: “always leave the campground cleaner than you found it.” If you find a mess on the ground, you clean it up regardless of who might have made it. You intentionally improve the environment for the next group of campers. (Actually, the original form of that rule, written by Robert Stephenson Smyth Baden-Powell, the father of scouting, was “Try and leave this world a little better than you found it.”) What if we followed a similar rule in our code: “Always check a module in cleaner than when you checked it out”? Regardless of who the original author was, what if we always made some effort, no matter how small, to improve the module? What would be the result?\n\nI think if we all followed that simple rule, we would see the end of the relentless deterioration of our software systems. Instead, our systems would gradually get better and better as they evolved. We would also see teams caring for the system as a whole, rather than just individuals caring for their own small part.\n\nI don’t think this rule is too much to ask. You don’t have to make every module perfect before you check it in. You simply have to make it a little bit better than when you checked it out. Of course, this means that any code you add to a module must be clean. It also means that you clean up at least one other thing before you check the module back in. You might simply improve the name of one variable, or split one long function into two smaller functions.\n\nYou might break a circular dependency, or add an interface to decouple policy from detail.\n\nFrankly, this just sounds like common decency to me—like washing your hands after you use the restroom, or putting your trash in the bin instead of dropping it on the floor. Indeed, the act of leaving a mess in the code should be as socially unacceptable as littering. It should be something that just isn’t done.\n\nBut it’s more than that. Caring for our own code is one thing. Caring for the team’s code is quite another. Teams help one another and clean up after one another. They follow the Boy Scout rule because it’s good for everyone, not just good for themselves."
    },
    {
      "title": "Check Your Code First Before Looking to Blame Others",
      "author": "Allan Kelly",
      "content": "Developers—all of us!—often have trouble believing our own code is broken. It is just so improbable that, for once, it must be the compiler that’s broken.\n\nYet, in truth, it is very (very) unusual that code is broken by a bug in the compiler, interpreter, OS, app server, database, memory manager, or any other piece of system software. Yes, these bugs exist, but they are far less common than we might like to believe.\n\nI once had a genuine problem with a compiler bug optimizing away a loop variable, but I have imagined my compiler or OS had a bug many more times. I have wasted a lot of my time, support time, and management time in the process, only to feel a little foolish each time it turned out to be my mistake after all.\n\nAssuming that the tools are widely used, mature, and employed in various technology stacks, there is little reason to doubt the quality. Of course, if the tool is an early release, or used by only a few people worldwide, or a piece of seldom downloaded, version 0.1, open source software, there may be good reason to suspect the software. (Equally, an alpha version of commercial software might be suspect.) Given how rare compiler bugs are, you are far better putting your time and energy into finding the error in your code than into proving that the compiler is wrong. All the usual debugging advice applies, so isolate the problem, stub out calls, and surround it with tests; check calling conventions, shared libraries, and version numbers; explain it to someone else; look out for stack corruption and variable type mismatches; and try the code on different machines and different build configurations, such as debug and release.\n\nQuestion your own assumptions and the assumptions of others. Tools from different vendors might have different assumptions built into them—so too might different tools from the same vendor.\n\nWhen someone else is reporting a problem you cannot duplicate, go and see what they are doing. They may be doing something you never thought of or are doing something in a different order.\n\nMy personal rule is that if I have a bug I can’t pin down, and I’m starting to think it’s the compiler, then it’s time to look for stack corruption. This is especially true if adding trace code makes the problem move around.\n\nMultithreaded problems are another source of bugs that turn hair gray and induce screaming at the machine. All the recommendations to favor simple code are multiplied when a system is multithreaded. Debugging and unit tests cannot be relied on to find such bugs with any consistency, so simplicity of design is paramount.\n\nSo, before you rush to blame the compiler, remember Sherlock Holmes’s advice, “Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth,” and opt for it over Dirk Gently’s, “Once you eliminate the improbable, whatever remains, no matter how impossible, must be the truth.”"
    },
    {
      "title": "Choose Your Tools with Care",
      "author": "Giovanni Asproni",
      "content": "Modern applications are very rarel y built from scratch. They are assembled using existing tools—components, libraries, and frameworks— for a number of good reasons:\n\n- Applications grow in size, complexity, and sophistication, while the time available to develop them grows shorter. It makes better use of developers’ time and intelligence if they can concentrate on writing more ­ business-domain code and less infrastructure code.\n\n- Widely used components and frameworks are likely to have fewer bugs than the ones developed in-house.\n\n- There is a lot of high-quality software available on the Web for free, which means lower development costs and greater likelihood of finding developers with the necessary interest and expertise.\n\n- Software production and maintenance is human-intensive work, so buying may be cheaper than building.\n\nHowever, choosing the right mix of tools for your application can be a tricky business requiring some thought. In fact, when making a choice, you should keep in mind a few things:\n\n- Different tools may rely on different assumptions about their context—e.g., surrounding infrastructure, control model, data model, communication protocols, etc.—which can lead to an architectural mismatch between the application and the tools. Such a mismatch leads to hacks and workarounds that will make the code more complex than necessary.\n\n- Different tools have different lifecycles, and upgrading one of them may become an extremely difficult and time-consuming task since the new functionality, design changes, or even bug fixes may cause incompatibilities with \n\nthe other tools. The greater the number of tools, the worse the problem can become.\n\n- Some tools require quite a bit of configuration, often by means of one or more XML files, which can grow out of control very quickly. The application may end up looking as if it was all written in XML plus a few odd lines of code in some programming language. The configurational complexity will make the application difficult to maintain and to extend.\n\n- Vendor lock-in occurs when code that depends heavily on specific vendor products ends up being constrained by them on several counts: maintainability, performances, ability to evolve, price, etc.\n\n- If you plan to use free software, you may discover that it’s not so free after all. You may need to buy commercial support, which is not necessarily going to be cheap.\n\n- Licensing terms matter, even for free software. For example, in some companies, it is not acceptable to use software licensed under the GNU license terms because of its viral nature—i.e., software developed with it must be distributed along with its source code.\n\nMy personal strategy to mitigate these problems is to start small by using only the tools that are absolutely necessary. Usually the initial focus is on removing the need to engage in low-level infrastructure programming (and problems), e.g., by using some middleware instead of using raw sockets for distributed applications. And then add more if needed. I also tend to isolate the external tools from my business domain objects by means of interfaces and layering, so that I can change the tool if I have to with a minimal amount of pain. A positive side effect of this approach is that I generally end up with a smaller application that uses fewer external tools than originally forecast."
    },
    {
      "title": "Code in the Language of the Domain",
      "author": "Dan North",
      "content": "Picture two codebases. In one, you come across: \n\n```if(portfolioIdsByTraderId.get(trader.getId()) .containsKey(portfolio.getId())) {...}```\n\n You scratch your head, wondering what this code might be for. It seems to be getting an ID from a trader object; using that to get a map out of a, well, mapof-maps, apparently; and then seeing if another ID from a portfolio object exists in the inner map. You scratch your head some more. You look for the declaration of portfolioIdsByTraderId and discover this: \n\n`Map<int, Map<int, int>> portfolioIdsByTraderId;`\n\n Gradually, you realize it might have something to do with whether a trader has access to a particular portfolio. And of course you will find the same lookup fragment—or, more likely, a similar but subtly different code fragment— whenever something cares whether a trader has access to a particular portfolio.\n\nIn the other codebase, you come across this: \n\n`if(trader.canView(portfolio)) {...}`\n\n No head scratching. You don’t need to know how a trader knows. Perhaps there is one of these maps-of-maps tucked away somewhere inside. But that’s the trader’s business, not yours.\n\nNow which of those codebases would you rather be working in?\n\nOnce upon a time, we only had very basic data structures: bits and bytes and characters (really just bytes, but we would pretend they were letters and punctuation). Decimals were a bit tricky because our base-10 numbers don’t work very well in binary, so we had several sizes of floating-point types. Then came arrays and strings (really just different arrays). Then we had stacks and queues and hashes and linked lists and skip lists and lots of other exciting data structures that don’t exist in the real world. “Computer science” was about spending \n\nlots of effort mapping the real world into our restrictive data structures. The real gurus could even remember how they had done it.\n\nThen we got user-defined types! OK, this isn’t news, but it does change the game somewhat. If your domain contains concepts like traders and portfolios, you can model them with types called, say, Trader and Portfolio. But, more importantly than this, you can model relationships between them using domain terms, too.\n\nIf you don’t code using domain terms, you are creating a tacit (read: secret) understanding that this int over here means the way to identify a trader, whereas that int over there means the way to identify a portfolio. (Best not to get them mixed up!) And if you represent a business concept (“Some traders are not allowed to view some portfolios—it’s illegal”) with an algorithmic snippet—say, an existence relationship in a map of keys—you aren’t doing the audit and compliance guys any favors.\n\nThe next programmer to come along might not be in on the secret, so why not make it explicit? Using a key as a lookup to another key that performs an existence check is not terribly obvious. How is someone supposed to intuit that’s where the business rules preventing conflict of interest are implemented?\n\nMaking domain concepts explicit in your code means other programmers can gather the intent of the code much more easily than by trying to retrofit an algorithm into what they understand about a domain. It also means that when the domain model evolves—which it will, as your understanding of the domain grows—you are in a good position to evolve the code. Coupled with good encapsulation, the chances are good that the rule will exist in only one place, and that you can change it without any of the dependent code being any the wiser.\n\nThe programmer who comes along a few months later to work on the code will thank you. The programmer who comes along a few months later might be you."
    },
    {
      "title": "Code Is Design",
      "author": "Ryan Brush",
      "content": "Imagine waking up tomorrow and learning that the construction industry has made the breakthrough of the century. Millions of cheap, incredibly fast robots can fabricate materials out of thin air, have a near-zero power cost, and can repair themselves. And it gets better: given an unambiguous blueprint for a construction project, the robots can build it without human intervention, all at negligible cost.\n\nOne can imagine the impact on the construction industry, but what would happen upstream? How would the behavior of architects and designers change if construction costs were negligible? Today, physical and computer models are built and rigorously tested before investing in construction. Would we bother if the construction was essentially free? If a design collapses, no big deal—just find out what went wrong and have our magical robots build another one.\n\nThere are further implications. With models obsolete, unfinished designs evolve by repeatedly building and improving upon an approximation of the end goal. A casual observer may have trouble distinguishing an unfinished design from a finished product.\n\nOur ability to predict timelines will fade away. Construction costs are more easily calculated than design costs—we know the approximate cost of installing a girder, and how many girders we need. As predictable tasks shrink toward zero, the less predictable design time starts to dominate. Results are produced more quickly, but reliable timelines slip away.\n\nOf course, the pressures of a competitive economy still apply. With construction costs eliminated, a company that can quickly complete a design gains an \n\nedge in the market. Getting design done fast becomes the central push of engineering firms. Inevitably, someone not deeply familiar with the design will see an unvalidated version, see the market advantage of releasing early, and say, “This looks good enough.” Some life-or-death projects will be more diligent, but in many cases, consumers learn to suffer through the incomplete design. Companies can always send out our magic robots to “patch” the broken buildings and vehicles they sell.\n\nAll of this points to a startlingly counterintuitive conclusion: our sole premise was a dramatic reduction in construction costs, with the result that quality got worse.\n\nIt shouldn’t surprise us that the preceding story has played out in software.\n\nIf we accept that code is design—a creative process rather than a mechanical one—the software crisis is explained. We now have a design crisis: the demand for quality, validated designs exceeds our capacity to create them. The pressure to use incomplete design is strong.\n\nFortunately, this model also offers clues to how we can get better. Physical simulations equate to automated testing; software design isn’t complete until it is validated with a brutal battery of tests. To make such tests more effective, we are finding ways to rein in the huge state space of large systems. Improved languages and design practices give us hope. Finally, there is one inescapable fact: great designs are produced by great designers dedicating themselves to the mastery of their craft. Code is no different."
    },
    {
      "title": "Code Layout Matters",
      "author": "Steve Freeman",
      "content": "An infeasible number of years ago, I worked on a cobol system where staff members weren’t allowed to change the indentation unless they already had a reason to change the code, because someone once broke something by letting a line slip into one of the special columns at the beginning of a line. This applied even if the layout was misleading, which it sometimes was, so we had to read the code very carefully because we couldn’t trust it. The policy must have cost a fortune in programmer drag.\n\nThere’s research suggesting that we all spend much more of our programming time navigating and reading code—finding where to make the change—than actually typing, so that’s what we want to optimize for. Here are three such optimizations: \n\n Easy to scan\n\nPeople are really good at visual pattern matching (a leftover trait from the time when we had to spot lions on the savannah), so I can help myself by making everything that isn’t directly relevant to the domain—all the “accidental complexity” that comes with most commercial languages— fade into the background by standardizing it. If code that behaves the same looks the same, then my perceptual system will help me pick out the differences. That’s why I also observe conventions about how to lay out the parts of a class within a compilation unit: constants, fields, public methods, private methods.\n\nExpressive layout\n\nWe’ve all learned to take the time to find the right names so that our code expresses as clearly as possible what it does, rather than just listing the steps—right? The code’s layout is part of this expressiveness, too. A first cut is to have the team agree on an automatic formatter for the basics, and then I might make adjustments by hand while I’m coding. Unless there’s active dissension, a team will quickly converge on a common “hand-finished” style. A formatter cannot understand my intentions (I should know, I once wrote one), and it’s more important to me that the line breaks and groupings reflect the intention of the code, not just the syntax of the language. (Kevin McGuire freed me from my bondage to automatic code formatters.)\n\n Compact format\n\nThe more I can get on a screen, the more I can see without breaking context by scrolling or switching files, which means I can keep less state in my head. Long procedure comments and lots of whitespace made sense for eight-character names and line printers, but now I live in an IDE that does syntax coloring and cross linking. Pixels are my limiting factor, so I want every one to contribute to my understanding of the code. I want the layout to help me understand the code, but no more than that.\n\nA nonprogrammer friend once remarked that code looks like poetry. I get that feeling from really good code—that everything in the text has a purpose, and that it’s there to help me understand the idea. Unfortunately, writing code doesn’t have the same romantic image as writing poetry."
    },
    {
      "title": "Code Layout Matters",
      "author": "Steve Freeman",
      "content": "An infeasible number of years ago, i worked on a cobol system where staff members weren’t allowed to change the indentation unless they already had a reason to change the code, because someone once broke something by letting a line slip into one of the special columns at the beginning of a line. This applied even if the layout was misleading, which it sometimes was, so we had to read the code very carefully because we couldn’t trust it. The policy must have cost a fortune in programmer drag.\n\nThere’s research suggesting that we all spend much more of our programming time navigating and reading code—finding *where* to make the change—than actually typing, so that’s what we want to optimize for. Here are three such optimizations: \n\n**Easy to scan**\n\nPeople are really good at visual pattern matching (a leftover trait from the time when we had to spot lions on the savannah), so I can help myself by making everything that isn’t directly relevant to the domain—all the “accidental complexity” that comes with most commercial languages— fade into the background by standardizing it. If code that behaves the same looks the same, then my perceptual system will help me pick out the differences. That’s why I also observe conventions about how to lay out the parts of a class within a compilation unit: constants, fields, public methods, private methods.\n\n**Expressive layout**\n\nWe’ve all learned to take the time to find the right names so that our code expresses as clearly as possible what it does, rather than just listing the steps—right? The code’s layout is part of this expressiveness, too. A first cut is to have the team agree on an automatic formatter for the basics, and then I might make adjustments by hand while I’m coding. Unless there’s active dissension, a team will quickly converge on a common “hand-finished” style. A formatter cannot understand my intentions (I should know, I once wrote one), and it’s more important to me that the line breaks and groupings reflect the intention of the code, not just the syntax of the language. (Kevin McGuire freed me from my bondage to automatic code formatters.)\n\n**Compact format**\n\nThe more I can get on a screen, the more I can see without breaking context by scrolling or switching files, which means I can keep less state in my head. Long procedure comments and lots of whitespace made sense for eight-character names and line printers, but now I live in an IDE that does syntax coloring and cross linking. Pixels are my limiting factor, so I want every one to contribute to my understanding of the code. I want the layout to help me understand the code, but no more than that.\n\nA nonprogrammer friend once remarked that code looks like poetry. I get that feeling from really good code—that everything in the text has a purpose, and that it’s there to help me understand the idea. Unfortunately, writing code doesn’t have the same romantic image as writing poetry."
    },
    {
      "title": "Code Reviews",
      "author": "Mattias Karlsson",
      "content": "You should do code reviews. Why? Because they *increase code quality* and *reduce defect rate*. But not necessarily for the reasons you might think.\n\nBecause they may previously have had some bad experiences with code reviews, many programmers tend to dislike them. I have seen organizations that require that all code pass a formal review before being deployed to production. Often, it is the architect or a lead developer doing this review, a practice that can be described as *architect reviews everything*. This is stated in the company’s software development process manual, so the programmers must comply.\n\nThere may be some organizations that need such a rigid and formal process, but most do not. In most organizations, such an approach is counterproductive.\n\nReviewees can feel like they are being judged by a parole board. Reviewers need both the time to read the code and the time to keep up to date with all the details of the system; they can rapidly become the bottleneck in this process, and the process soon degenerates.\n\nInstead of simply correcting mistakes in code, the purpose of code reviews should be to *share knowledge* and establish common coding guidelines. Sharing your code with other programmers enables collective code ownership. Let a random team member *walk through the code* with the rest of the team.\n\nInstead of looking for errors, you should review the code by trying to learn and understand it.\n\nBe gentle during code reviews. Ensure that comments are *constructive, not caustic*. Introduce different roles for the review meeting to avoid having organizational seniority among team members affect the code review. Examples of roles could include having one reviewer focus on documentation, another on exceptions, and a third to look at the functionality. This approach helps to spread the review burden across the team members.\n\nHave a regular *code review day* each week. Spend a couple of hours in a review meeting. Rotate the reviewee every meeting in a simple round-robin pattern. Remember to switch roles among team members every review meeting, too.\n\n*Involve newbies* in code reviews. They may be inexperienced, but their fresh university knowledge can provide a different perspective. *Involve experts* for their experience and knowledge. They will identify error-prone code faster and with more accuracy. Code reviews will flow more easily if the team has coding conventions that are checked by tools. That way, code formatting will never be discussed during the code review meeting.\n\n*Making code reviews* fun is perhaps the most important contributor to success. Reviews are about the people reviewing. If the review meeting is painful or dull, it will be hard to motivate anyone. Make it an *informal code review* whose principal purpose is to share knowledge among team members. Leave sarcastic comments outside, and bring a cake or brown-bag lunch instead."
    },
    {
      "title": "Coding with Reason",
      "author": "Yechiel Kimchi",
      "content": "Trying to reason about software correctness by hand results in a formal proof that is longer than the code, and more likely to contain errors. Automated tools are preferable but not always possible. What follows describes a middle path: reasoning semiformally about correctness.\n\nThe underlying approach is to divide all the code under consideration into short sections—from a single line, such as a function call, to blocks of less than 10 lines—and argue about their correctness. The arguments need only be strong enough to convince your devil’s advocate peer programmer.\n\nA section should be chosen so that at each endpoint, the state of the program (namely, the program counter and the values of all “living” objects) satisfies an easily described property, and so that the functionality of that section (state transformation) is easy to describe as a single task; these guidelines will make reasoning simpler. Such endpoint properties generalize concepts like preconditions and postconditions for functions, and invariants for loops and classes (with respect to their instances). Striving for sections to be as independent of one another as possible simplifies reasoning and is indispensable when these sections are to be modified.\n\nMany of the coding practices that are well known (although perhaps less well followed) and considered “good” make reasoning easier. Hence, just by intending to reason about your code, you already start moving toward a better style and structure. Unsurprisingly, most of these practices can be checked by static code analyzers:\n\n- Avoid using goto statements, as they make remote sections highly interdependent.\n\n- Avoid using modifiable global variables, as they make all sections that use them dependent.\n\n- Each variable should have the smallest possible scope. For example, a local object can be declared right before its first usage.\n\n- Make objects immutable whenever relevant.\n\n- Make the code readable by using spacing, both horizontal and vertical—e.g., aligning related structures and using an empty line to separate two sections.\n\n- Make the code self-documenting by choosing descriptive (but relatively short) names for objects, types, functions, etc.\n\n- If you need a nested section, make it a function.\n\n- Make your functions short and focused on a single task. The old 24-line limit still applies. Although screen size and resolution have changed, nothing has changed in human cognition since the 1960s.\n\n- Functions should have few parameters (four is a good upper bound). This does not restrict the data communicated to functions: grouping related parameters into a single object localizes object invariants, which simplifies reasoning with respect to their coherence and consistency.\n\n- More generally, each unit of code, from a block to a library, should have a narrow interface. Less communication reduces the reasoning required. This means that getters that return internal state are a liability—don’t ask an object for information to work with. Instead, ask the object to do the work with the information it already has. In other words, encapsulation is all—and only—about narrow interfaces.\n\n- In order to preserve class invariants, usage of setters should be discouraged. Setters tend to allow invariants that govern an object’s state to be broken.\n\nAs well as reasoning about its correctness, arguing about your code helps you better understand it. Communicate the insights you gain for everyone’s benefit."
    },
    {
      "title": "A Comment on Comments",
      "author": "Cal Evans",
      "content": "In my first programming class in college, my teacher handed out two basic coding sheets. On the board, the assignment read, “Write a program to input and average 10 bowling scores.” Then the teacher left the room.\n\nHow hard could this be? I don’t remember my final solution, but I’m sure it had a `FOR/NEXT` loop in it and couldn’t have been more than 15 lines long in total.\n\nCoding sheets—for you kids reading this, yes, we used to write code out longhand before actually entering it into a computer—allowed for around 70 lines of code each. I was very confused as to why the teacher would have given us two sheets. Since my handwriting has always been atrocious, I used the second one to recopy my code very neatly, hoping to get a couple of extra points for style.\n\nMuch to my surprise, when I received the assignment back at the start of the next class, I received a barely passing grade. (It was to be an omen to me for the rest of my time in college.) Scrawled across the top of my neatly copied code was “No comments?” It was not enough that the teacher and I both knew what the program was supposed to do. Part of the point of the assignment was to teach me that my code should explain itself to the next programmer coming behind me. It’s a lesson I’ve not forgotten.\n\nComments are not evil. They are as necessary to programming as basic branching or looping constructs. Most modern languages have a tool akin to javadoc that will parse properly formatted comments to automatically build an API document. This is a very good start, but not nearly enough. Inside your code should be explanations about what the code is supposed to be doing. Coding by the old adage, “If it was hard to write, it should be hard to read,” does a disservice to your client, your employer, your colleagues, and your future self.\n\nOn the other hand, you can go too far in your commenting. Make sure that your comments clarify your code but do not obscure it. Sprinkle your code with relevant comments explaining what the code is supposed to accomplish.\n\nYour header comments should give any programmer enough information to use your code without having to read it, while your inline comments should assist the next developer in fixing or extending it.\n\nAt one job, I disagreed with a design decision made by those above me. Feeling rather snarky, as young programmers often do, I pasted the text of the email instructing me to use their design into the header comment block of the file. It turned out that managers at this particular shop actually reviewed the code when it was committed. It was my first introduction to the term *career-limiting move*."
    },
    {
      "title": "Comment Only What the Code Cannot Say",
      "author": "Kevlin Henney",
      "content": "The difference between theory and practice is greater in practice than it is in theory—an observation that certainly applies to comments. In theory, the general idea of commenting code sounds like a worthy one: offer the reader detail, an explanation of what’s going on. What could be more helpful than being helpful? In practice, however, comments often become a blight.\n\nAs with any other form of writing, there is a skill to writing good comments.\n\nMuch of the skill is in knowing when not to write them.\n\nWhen code is ill-formed, compilers, interpreters, and other tools will be sure to object. If the code is in some way functionally incorrect, reviews, static analysis, tests, and day-to-day use in a production environment will flush most bugs out. But what about comments? In *The Elements of Programming Style* (Computing McGraw-Hill), Kernighan and Plauger note that “a comment is of zero (or negative) value if it is wrong.” And yet such comments often litter and survive in a codebase in a way that coding errors never could.\n\nThey provide a constant source of distraction and misinformation, a subtle but constant drag on a programmer’s thinking.\n\nWhat of comments that are not technically wrong, but add no value to the code? Such comments are noise. Comments that parrot the code offer nothing extra to the reader—stating something once in code and again in natural language does not make it any truer or more real. Commented-out code is not executable code, so it has no useful effect for either reader or runtime. It also becomes stale very quickly. Version-related comments and commented-out code try to address questions of versioning and history. These questions have already been answered (far more effectively) by version control tools.\n\nA prevalence of noisy comments and incorrect comments in a codebase encourages programmers to ignore all comments, either by skipping past them or by taking active measures to hide them. Programmers are resourceful and will route around anything perceived to be damage: folding comments up; switching coloring scheme so that comments and the background are the same color; scripting to filter out comments. To save a codebase from such misapplications of programmer ingenuity, and to reduce the risk of overlooking any comments of genuine value, comments should be treated as though they were code. Each comment should add some value for the reader, otherwise it is waste that should be removed or rewritten.\n\nWhat then qualifies as value? Comments should say something code does not and cannot say. A comment explaining what a piece of code should already say is an invitation to change code structure or coding conventions so the code speaks for itself. Instead of compensating for poor method or class names, rename them. Instead of commenting sections in long functions, extract smaller functions whose names capture the former sections’ intent. Try to express as much as possible through code. Any shortfall between what you can express in code and what you would like to express in total becomes a plausible candidate for a useful comment. Comment what the code *cannot* say, not simply what it does not say."
    },
    {
      "title": "Continuous Learning",
      "author": "Clint Shank",
      "content": "We live in interesting times. As development gets distributed across the globe, you learn there are lots of people capable of doing your job. You need to keep learning to stay marketable. Otherwise you’ll become a dinosaur, stuck in the same job until, one day, you’ll no longer be needed or your job gets outsourced to some cheaper resource.\n\nSo what do you do about it? Some employers are generous enough to provide training to broaden your skill set. Others may not be able to spare the time or money for any training at all. To play it safe, you need to take responsibility for your own education.\n\nHere’s a list of ways to keep you learning. Many of these can be found on the Internet for free:\n\n- Read books, magazines, blogs, Twitter feeds, and websites. If you want to go deeper into a subject, consider joining a mailing list or newsgroup. If you really want to get immersed in a technology, get hands on—write some code.\n\n- Always try to work with a mentor, as being the top guy can hinder your education. Although you can learn something from anybody, you can learn a whole lot more from someone smarter or more experienced than you. If you can’t find a mentor, consider moving on.\n\n- Use virtual mentors. Find authors and developers on the Web who you really like and read everything they write. Subscribe to their blogs.\n\n- Get to know the frameworks and libraries you use. Knowing how something works makes you know how to use it better. If they’re open source, you’re really in luck. Use the debugger to step through the code to see what’s going on under the hood. You’ll get to see code written and reviewed by some really smart people.\n\n- Whenever you make a mistake, fix a bug, or run into a problem, try to really understand what happened. It’s likely that someone else ran into the same problem and posted it on the Web. Google is really useful here.\n\n- A good way to learn something is to teach or speak about it. When people are going to listen to you and ask you questions, you’ll be highly motivated to learn. Try a lunch-’n’-learn at work, a user group, or a local conference.\n\n- Join or start a study group (à la patterns community) or a local user group for a language, technology, or discipline you are interested in.\n\n- Go to conferences. And if you can’t go, many conferences put their talks online for free.\n\n- Long commute? Listen to podcasts.\n\n- Ever run a static analysis tool over the codebase or look at the warnings in your IDE? Understand what they’re reporting and why.\n\n- Follow the advice of *the Pragmatic Programmers* and learn a new language every year. At least learn a new technology or tool. Branching out gives you new ideas you can use in your current technology stack.\n\n- Not everything you learn has to be about technology. Learn the domain you’re working in so you can better understand the requirements and help solve the business problem. Learning how to be more productive— how to work better—is another good option.\n\n- Go back to school.\n\nIt would be nice to have the capability that Neo had in The Matrix, and simply download the information we need into our brains. But we don’t, so it will take a time commitment. You don’t have to spend every waking hour learning. A little time—say, each week—is better than nothing. There is (or should be) a life outside of work.\n\nTechnology changes fast. Don’t get left behind."
    },
    {
      "title": "Convenience Is Not an -ility",
      "author": "Gregor Hohpe",
      "content": "Much has been said about the importance and challenges of designing good apis. It’s difficult to get right the first time and it’s even more difficult to change later—sort of like raising children. Most experienced programmers have learned that a good API follows a consistent level of abstraction, exhibits consistency and symmetry, and forms the vocabulary for an expressive language. Alas, being aware of the guiding principles does not automatically translate into appropriate behavior. Eating sweets is bad for you.\n\nInstead of preaching from on high, I want to pick on a particular API design “strategy,” one that I encounter time and again: the argument of convenience.\n\nIt typically begins with one of the following “insights”:\n\n- I don’t want other classes to have to make two separate calls to do this one thing.\n\n- Why should I make another method if it’s almost the same as this method?\n\nI’ll just add a simple switch.\n\n- See, it’s very easy: if the second string parameter ends with “.txt”, the method automatically assumes that the first parameter is a filename, so I really don’t need two methods.\n\nWhile well intended, such arguments are prone to decrease the readability of code using the API. A method invocation like:\n\n`parser.processNodes(text, false);`\n\nis virtually meaningless without knowing the implementation or at least consulting the documentation. This method was likely designed for the convenience of the implementer as opposed to the convenience of the caller—“I don’t want the caller to have to make two separate calls” translated into “I didn’t want to code up two separate methods.” There’s nothing fundamentally wrong with convenience if it’s intended to be the antidote to tediousness, clunkiness, or awkwardness. However, if we think a bit more carefully about it, the antidote to those symptoms is efficiency, consistency, and elegance, not necessarily convenience. APIs are supposed to hide underlying complexity, so we can realistically expect good API design to require some effort. A single large method could certainly be more convenient to write than a well-thought-out set of operations, but would it be easier to use?\n\nThe metaphor of API as a language can guide us toward better design decisions in these situations. An API should provide an expressive language, which gives the next layer above sufficient vocabulary to ask and answer useful questions.\n\nThis does not imply that it should provide exactly one method, or verb, for each question that may be worth asking. A diverse vocabulary allows us to express subtleties in meaning. For example, we prefer to say `run` instead of `walk(true)`, even though it could be viewed as essentially the same operation, just executed at different speeds. A consistent and well-thought-out API vocabulary makes for expressive and easy-to-understand code in the next layer up. More importantly, a composable vocabulary allows other programmers to use the API in ways you may not have anticipated—a great convenience indeed for the users of the API! Next time you are tempted to lump a few things together into one API method, remember that the English language does not have one word for `MakeUpYourRoomBeQuietAndDoYourHomeWork`, even though it would be really convenient for such a frequently requested operation."
    },
    {
      "title": "Deploy Early and Often",
      "author": "Steve Berczuk",
      "content": "Debugging the deployment and installation processes is often put off until close to the end of a project. In some projects, writing installation tools is delegated to a release engineer who takes on the task as a “necessary evil.” Reviews and demonstrations are done from a hand-crafted environment to ensure that everything works. The result is that the team gets no experience with the deployment process or the deployed environment until it may be too late to make changes.\n\nThe installation/deployment process is the first thing that the customer sees, and a simple one is the first step to having a reliable (or, at least, easy to debug) production environment. The deployed software is what the customer will use. By not ensuring that the deployment sets up the application correctly, you’ll raise questions with your customers before they get to use your software thoroughly.\n\nStarting your project with an installation process will give you time to evolve the process as you move through the product development cycle, and the chance to make changes to the application code to make the installation easier.\n\nRunning and testing the installation process on a clean environment periodically also provides a check that you have not made assumptions in the code that rely on the development or test environments.\n\nPutting deployment last means that the deployment process may need to be more complicated to work around assumptions in the code. What seemed a great idea in an IDE, where you have full control over an environment, might make for a much more complicated deployment process. It is better to know all the trade-offs sooner rather than later.\n\nWhile “being able to deploy” doesn’t seem to have a lot of business value early on as compared to seeing an application run on a developer’s laptop, the simple truth is that until you can demonstrate you application on the target environment, there is a lot of work to do before you can deliver business value. If your rationale for putting off a deployment process is that it is trivial, then do it anyway since it is low cost. If it’s too complicated, or if there are too many uncertainties, do what you would do with application code: experiment, evaluate, and refactor the deployment process as you go.\n\nThe installation/deployment process is essential to the productivity of your customers or your professional services team, so you should be testing and refactoring this process as you go. We test and refactor the source code throughout a project. The deployment deserves no less."
    },
    {
      "title": "Distinguish Business Exceptions from Technical",
      "author": "Dan Bergh Johnsson",
      "content": "There are basically two reasons that things go wrong at runtime: technical problems that prevent us from using the application and business logic that prevents us from misusing the application. Most modern languages, such as LISP, Java, Smalltalk, and C#, use exceptions to signal both these situations. However, the two situations are so different that they should be carefully held apart. It is a potential source of confusion to represent them both using the same exception hierarchy, not to mention the same exception class.\n\nAn unresolvable technical problem can occur when there is a programming error. For example, if you try to access element 83 from an array of size 17, then the program is clearly off track, and some exception should result. The subtler version is calling some library code with inappropriate arguments, causing the same situation on the inside of the library.\n\nIt would be a mistake to attempt to resolve these situations you caused yourself. Instead, we let the exception bubble up to the highest architectural level and let some general exception-handling mechanism do what it can to ensure that the system is in a safe state, such as rolling back a transaction, logging and alerting administration, and reporting back (politely) to the user.\n\nA variant of this situation is when you are in the “library situation” and a caller has broken the contract of your method, e.g., passing a totally bizarre argument or not having a dependent object set up properly. This is on a par with accessing the 83rd element from 17: the caller should have checked; not doing so is a programmer error on the client side. The proper response is to throw a technical exception.\n\nA different, but still technical, situation is when the program cannot proceed because of a problem in the execution environment, such as an unresponsive database. In this situation, you must assume that the infrastructure did what it could to resolve the issue—repairing connections and retrying a reasonable number of times—and failed. Even if the cause is different, the situation for the calling code is similar: there is little it can do about it. So, we signal the situation through an exception that we let bubble up to the general exception-handling mechanism.\n\nIn contrast to these, we have the situation where you cannot complete the call for a domain-logical reason. In this case, we have encountered a situation that is an exception, i.e., unusual and undesirable, but not bizarre or programmatically in error (for example, if I try to withdraw money from an account with insufficient funds). In other words, this kind of situation is a part of the contract, and throwing an exception is just an alternative return path that is part of the model and that the client should be aware of and be prepared to handle.\n\nFor these situations, it is appropriate to create a specific exception or a separate exception hierarchy so that the client can handle the situation on its own terms.\n\nMixing technical exceptions and business exceptions in the same hierarchy blurs the distinction and confuses the caller about what the method contract is, what conditions it is required to ensure before calling, and what situations it is supposed to handle. Separating the cases gives clarity and increases the chances that technical exceptions will be handled by some application framework, while the business domain exceptions actually are considered and handled by the client code."
    },
    {
      "title": "Do Lots of Deliberate Practice",
      "author": "Jon Jagger",
      "content": "Deliberate practice is not simply performing a task. If you ask yourself, “Why am I performing this task?” and your answer is, “To complete the task,” then you’re not doing deliberate practice.\n\nYou do deliberate practice to improve your ability to perform a task. It’s about skill and technique. Deliberate practice means repetition. It means performing the task with the aim of increasing your mastery of one or more aspects of the task. It means repeating the repetition. Slowly, over and over again, until you achieve your desired level of mastery. You do deliberate practice to master the task, not to complete the task.\n\nThe principal aim of paid development is to finish a product, whereas the principal aim of deliberate practice is to improve your performance. They are not the same. Ask yourself, how much of your time do you spend developing someone else’s product? How much developing yourself?\n\nHow much deliberate practice does it take to acquire expertise?\n\n- Peter Norvig writes* that “it may be that 10,000 hours…is the magic number.”\n\n- In *Leading Lean Software Development* (Addison-Wesley Professional), Mary Poppendieck notes that “it takes elite performers a minimum of 10,000 hours of deliberate focused practice to become experts.”\n\nThe expertise arrives gradually over time—not all at once in the 10,000th hour! Nevertheless, 10,000 hours is a lot: about 20 hours per week for 10 years.\n\nGiven this level of commitment, you might be worrying that you’re just not expert material. You are. Greatness is largely a matter of conscious choice.\n\nYour choice. Research over the last two decades has shown that the main factor in acquiring expertise is time spent doing deliberate practice. Innate ability is not the main factor. According to Mary Poppendieck: There is broad consensus among researchers of expert performance that inborn talent does not account for much more than a threshold; you have to have a minimum amount of natural ability to get started in a sport or profession. After that, the people who excel are the ones who work the hardest.\n\nThere is little point to deliberately practicing something you are already an expert at. Deliberate practice means practicing something you are not good at. Peter Norvig explains: \n\n> The key [to developing expertise] is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes.\n\nAnd Mary Poppendieck writes: \n\n> Deliberate practice does not mean doing what you are good at; it means challenging yourself, doing what you are not good at. So it’s not necessarily fun.\n\nDeliberate practice is about learning—learning that changes you, learning that changes your behavior. Good luck."
    }
  ]
}